{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OECmoA7We-9d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9j-HbUobtwvE"
   },
   "outputs": [],
   "source": [
    "# Load the class labels\n",
    "LABELS = open(\"data/object_detection_classes_yolov3.txt\").read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4y3eIOxJueXM"
   },
   "outputs": [],
   "source": [
    "weightsPath = os.path.join(\"data/yolov3.weights\")\n",
    "configPath = os.path.join(\"data/yolov3.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VQb6pBa7uoqv"
   },
   "outputs": [],
   "source": [
    "# Loading the neural network framework Darknet (YOLO was created based on this framework)\n",
    "net = cv2.dnn.readNetFromDarknet(configPath,weightsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display function to show image\n",
    "def display_img(img,cmap=None):\n",
    "    fig = plt.figure(figsize = (12,12))\n",
    "    plt.axis(False)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img,cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "LqH9GSahuuFX"
   },
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    \n",
    "    # initialize a list of colors to represent each possible class label\n",
    "    np.random.seed(42)\n",
    "    image2 = image.copy()\n",
    "    COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")\n",
    "    (H, W) = image.shape[:2]\n",
    "    \n",
    "    # determine only the \"ouput\" layers name which we need from YOLO\n",
    "    ln = net.getLayerNames()\n",
    "    ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    \n",
    "    # construct a blob from the input image and then perform a forward pass of the YOLO object detector, \n",
    "    # giving us our bounding boxes and associated probabilities\n",
    "    blob = cv2.dnn.blobFromImage(image2, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layerOutputs = net.forward(ln)\n",
    "    \n",
    "    output_list = []\n",
    "    boxes = []\n",
    "    coord = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "    classes = []\n",
    "    box_label_list=[]\n",
    "    threshold = 0.2\n",
    "    # loop over each of the layer outputs\n",
    "    for output in layerOutputs:\n",
    "        # loop over each of the detections\n",
    "        for detection in output:\n",
    "            # extract the class ID and confidence (i.e., probability) of\n",
    "            # the current object detection\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "\n",
    "            # filter out weak predictions by ensuring the detected\n",
    "            # probability is greater than the minimum probability\n",
    "            # confidence type=float, default=0.5\n",
    "            if confidence > threshold:\n",
    "                # scale the bounding box coordinates back relative to the\n",
    "                # size of the image, keeping in mind that YOLO actually\n",
    "                # returns the center (x, y)-coordinates of the bounding\n",
    "                # box followed by the boxes' width and height\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                # use the center (x, y)-coordinates to derive the top and\n",
    "                # and left corner of the bounding box\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                # update our list of bounding box coordinates, confidences,\n",
    "                # and class IDs\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "\n",
    "    # apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, threshold, 0.1)\n",
    "\n",
    "    # ensure at least one detection exists\n",
    "    if len(idxs) > 0:\n",
    "      \n",
    "      # loop over the indexes we are keeping\n",
    "      for i in idxs.flatten():\n",
    "        (x, y) = (boxes[i][0], boxes[i][1])\n",
    "        (w, h) = (boxes[i][2], boxes[i][3])\n",
    "           \n",
    "        coord.append([x,y,w,h])\n",
    "\n",
    "        #for image cropping\n",
    "        output_list.append(image.copy()[y:y+h, x:x+w])\n",
    "\n",
    "        #prepare list of labels \n",
    "        box_label_list.append(LABELS[classIDs[i]])\n",
    "\n",
    "      #take care of duplicates\n",
    "      dups = {}\n",
    "      for j, val in enumerate(box_label_list):\n",
    "        if val not in dups:\n",
    "          #store index of first occurence and occurence value\n",
    "          dups[val] = [j, 1]\n",
    "        else:\n",
    "          #special case for first occurence\n",
    "          if dups[val][1] ==1:\n",
    "            box_label_list[dups[val][0]] += str(dups[val][1])\n",
    "\n",
    "          #increment occurence value, index value doesn't matter anymore\n",
    "          dups[val][1] += 1\n",
    "            \n",
    "          #use stored occurence value\n",
    "          box_label_list[j] += str(dups[val][1])\n",
    "\n",
    "      for k in range(len(box_label_list)):\n",
    "        # draw a bounding box rectangle and label on the image\n",
    "        x = coord[k][0]\n",
    "        y = coord[k][1]\n",
    "        w = coord[k][2]\n",
    "        h = coord[k][3]\n",
    "        color = (255,0,0)\n",
    "        cv2.rectangle(image2, (x, y), (x + w, y + h), color, 2)\n",
    "        text = box_label_list[k]\n",
    "        cv2.putText(image2, text, (x +15, y + 20), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "        classes.append(text)\n",
    "        \n",
    "    return image2, coord, classes, output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Ts6Qfn8C7OaU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['couch', 'potted plant']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7ca22d896586>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_list\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "dict({classes, output_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dict( zip( classes, output_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['couch', 'potted plant']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 85, 102,  86],\n",
       "        [113, 130, 114],\n",
       "        [102, 119, 103],\n",
       "        ...,\n",
       "        [179, 181, 180],\n",
       "        [179, 181, 180],\n",
       "        [178, 180, 179]],\n",
       "\n",
       "       [[ 89, 106,  90],\n",
       "        [104, 121, 105],\n",
       "        [ 86, 103,  87],\n",
       "        ...,\n",
       "        [179, 181, 180],\n",
       "        [178, 180, 179],\n",
       "        [178, 180, 179]],\n",
       "\n",
       "       [[ 89, 106,  90],\n",
       "        [ 92, 109,  93],\n",
       "        [ 60,  77,  61],\n",
       "        ...,\n",
       "        [178, 180, 179],\n",
       "        [178, 180, 179],\n",
       "        [177, 179, 178]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 59,  34,  27],\n",
       "        [ 58,  33,  28],\n",
       "        [ 60,  37,  31],\n",
       "        ...,\n",
       "        [141, 124, 116],\n",
       "        [140, 123, 115],\n",
       "        [139, 122, 114]],\n",
       "\n",
       "       [[ 58,  31,  24],\n",
       "        [ 55,  30,  25],\n",
       "        [ 54,  31,  25],\n",
       "        ...,\n",
       "        [142, 125, 117],\n",
       "        [142, 125, 117],\n",
       "        [141, 124, 116]],\n",
       "\n",
       "       [[ 59,  32,  25],\n",
       "        [ 57,  32,  27],\n",
       "        [ 56,  33,  27],\n",
       "        ...,\n",
       "        [144, 127, 119],\n",
       "        [144, 127, 119],\n",
       "        [143, 126, 118]]], dtype=uint8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['couch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Object Detection with BB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
